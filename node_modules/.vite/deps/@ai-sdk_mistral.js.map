{
  "version": 3,
  "sources": ["../../.pnpm/@ai-sdk+mistral@0.0.43_zod@3.24.1/node_modules/@ai-sdk/mistral/src/mistral-facade.ts", "../../.pnpm/@ai-sdk+mistral@0.0.43_zod@3.24.1/node_modules/@ai-sdk/mistral/src/mistral-chat-language-model.ts", "../../.pnpm/@ai-sdk+mistral@0.0.43_zod@3.24.1/node_modules/@ai-sdk/mistral/src/convert-to-mistral-chat-messages.ts", "../../.pnpm/@ai-sdk+mistral@0.0.43_zod@3.24.1/node_modules/@ai-sdk/mistral/src/map-mistral-finish-reason.ts", "../../.pnpm/@ai-sdk+mistral@0.0.43_zod@3.24.1/node_modules/@ai-sdk/mistral/src/mistral-error.ts", "../../.pnpm/@ai-sdk+mistral@0.0.43_zod@3.24.1/node_modules/@ai-sdk/mistral/src/get-response-metadata.ts", "../../.pnpm/@ai-sdk+mistral@0.0.43_zod@3.24.1/node_modules/@ai-sdk/mistral/src/mistral-provider.ts", "../../.pnpm/@ai-sdk+mistral@0.0.43_zod@3.24.1/node_modules/@ai-sdk/mistral/src/mistral-embedding-model.ts"],
  "sourcesContent": ["import { loadApiKey, withoutTrailingSlash } from '@ai-sdk/provider-utils';\nimport { MistralChatLanguageModel } from './mistral-chat-language-model';\nimport {\n  MistralChatModelId,\n  MistralChatSettings,\n} from './mistral-chat-settings';\nimport { MistralProviderSettings } from './mistral-provider';\n\n/**\n * @deprecated Use `createMistral` instead.\n */\nexport class Mistral {\n  /**\n   * Base URL for the Mistral API calls.\n   */\n  readonly baseURL: string;\n\n  readonly apiKey?: string;\n\n  readonly headers?: Record<string, string>;\n\n  /**\n   * Creates a new Mistral provider instance.\n   */\n  constructor(options: MistralProviderSettings = {}) {\n    this.baseURL =\n      withoutTrailingSlash(options.baseURL ?? options.baseUrl) ??\n      'https://api.mistral.ai/v1';\n\n    this.apiKey = options.apiKey;\n    this.headers = options.headers;\n  }\n\n  private get baseConfig() {\n    return {\n      baseURL: this.baseURL,\n      headers: () => ({\n        Authorization: `Bearer ${loadApiKey({\n          apiKey: this.apiKey,\n          environmentVariableName: 'MISTRAL_API_KEY',\n          description: 'Mistral',\n        })}`,\n        ...this.headers,\n      }),\n    };\n  }\n\n  chat(modelId: MistralChatModelId, settings: MistralChatSettings = {}) {\n    return new MistralChatLanguageModel(modelId, settings, {\n      provider: 'mistral.chat',\n      ...this.baseConfig,\n    });\n  }\n}\n", "import {\n  LanguageModelV1,\n  LanguageModelV1CallWarning,\n  LanguageModelV1FinishReason,\n  LanguageModelV1StreamPart,\n} from '@ai-sdk/provider';\nimport {\n  FetchFunction,\n  ParseResult,\n  combineHeaders,\n  createEventSourceResponseHandler,\n  createJsonResponseHandler,\n  postJsonToApi,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod';\nimport { convertToMistralChatMessages } from './convert-to-mistral-chat-messages';\nimport { mapMistralFinishReason } from './map-mistral-finish-reason';\nimport {\n  MistralChatModelId,\n  MistralChatSettings,\n} from './mistral-chat-settings';\nimport { mistralFailedResponseHandler } from './mistral-error';\nimport { getResponseMetadata } from './get-response-metadata';\n\ntype MistralChatConfig = {\n  provider: string;\n  baseURL: string;\n  headers: () => Record<string, string | undefined>;\n  fetch?: FetchFunction;\n};\n\nexport class MistralChatLanguageModel implements LanguageModelV1 {\n  readonly specificationVersion = 'v1';\n  readonly defaultObjectGenerationMode = 'json';\n  readonly supportsImageUrls = false;\n\n  readonly modelId: MistralChatModelId;\n  readonly settings: MistralChatSettings;\n\n  private readonly config: MistralChatConfig;\n\n  constructor(\n    modelId: MistralChatModelId,\n    settings: MistralChatSettings,\n    config: MistralChatConfig,\n  ) {\n    this.modelId = modelId;\n    this.settings = settings;\n    this.config = config;\n  }\n\n  get provider(): string {\n    return this.config.provider;\n  }\n\n  private getArgs({\n    mode,\n    prompt,\n    maxTokens,\n    temperature,\n    topP,\n    topK,\n    frequencyPenalty,\n    presencePenalty,\n    stopSequences,\n    responseFormat,\n    seed,\n  }: Parameters<LanguageModelV1['doGenerate']>[0]) {\n    const type = mode.type;\n\n    const warnings: LanguageModelV1CallWarning[] = [];\n\n    if (topK != null) {\n      warnings.push({\n        type: 'unsupported-setting',\n        setting: 'topK',\n      });\n    }\n\n    if (frequencyPenalty != null) {\n      warnings.push({\n        type: 'unsupported-setting',\n        setting: 'frequencyPenalty',\n      });\n    }\n\n    if (presencePenalty != null) {\n      warnings.push({\n        type: 'unsupported-setting',\n        setting: 'presencePenalty',\n      });\n    }\n\n    if (stopSequences != null) {\n      warnings.push({\n        type: 'unsupported-setting',\n        setting: 'stopSequences',\n      });\n    }\n\n    if (\n      responseFormat != null &&\n      responseFormat.type === 'json' &&\n      responseFormat.schema != null\n    ) {\n      warnings.push({\n        type: 'unsupported-setting',\n        setting: 'responseFormat',\n        details: 'JSON response format schema is not supported',\n      });\n    }\n\n    const baseArgs = {\n      // model id:\n      model: this.modelId,\n\n      // model specific settings:\n      safe_prompt: this.settings.safePrompt,\n\n      // standardized settings:\n      max_tokens: maxTokens,\n      temperature,\n      top_p: topP,\n      random_seed: seed,\n\n      // response format:\n      response_format:\n        responseFormat?.type === 'json' ? { type: 'json_object' } : undefined,\n\n      // messages:\n      messages: convertToMistralChatMessages(prompt),\n    };\n\n    switch (type) {\n      case 'regular': {\n        return {\n          args: { ...baseArgs, ...prepareToolsAndToolChoice(mode) },\n          warnings,\n        };\n      }\n\n      case 'object-json': {\n        return {\n          args: {\n            ...baseArgs,\n            response_format: { type: 'json_object' },\n          },\n          warnings,\n        };\n      }\n\n      case 'object-tool': {\n        return {\n          args: {\n            ...baseArgs,\n            tool_choice: 'any',\n            tools: [{ type: 'function', function: mode.tool }],\n          },\n          warnings,\n        };\n      }\n\n      default: {\n        const _exhaustiveCheck: never = type;\n        throw new Error(`Unsupported type: ${_exhaustiveCheck}`);\n      }\n    }\n  }\n\n  async doGenerate(\n    options: Parameters<LanguageModelV1['doGenerate']>[0],\n  ): Promise<Awaited<ReturnType<LanguageModelV1['doGenerate']>>> {\n    const { args, warnings } = this.getArgs(options);\n\n    const { responseHeaders, value: response } = await postJsonToApi({\n      url: `${this.config.baseURL}/chat/completions`,\n      headers: combineHeaders(this.config.headers(), options.headers),\n      body: args,\n      failedResponseHandler: mistralFailedResponseHandler,\n      successfulResponseHandler: createJsonResponseHandler(\n        mistralChatResponseSchema,\n      ),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    const { messages: rawPrompt, ...rawSettings } = args;\n    const choice = response.choices[0];\n    let text = choice.message.content ?? undefined;\n\n    // when there is a trailing assistant message, mistral will send the\n    // content of that message again. we skip this repeated content to\n    // avoid duplication, e.g. in continuation mode.\n    const lastMessage = rawPrompt[rawPrompt.length - 1];\n    if (\n      lastMessage.role === 'assistant' &&\n      text?.startsWith(lastMessage.content)\n    ) {\n      text = text.slice(lastMessage.content.length);\n    }\n\n    return {\n      text,\n      toolCalls: choice.message.tool_calls?.map(toolCall => ({\n        toolCallType: 'function',\n        toolCallId: toolCall.id,\n        toolName: toolCall.function.name,\n        args: toolCall.function.arguments!,\n      })),\n      finishReason: mapMistralFinishReason(choice.finish_reason),\n      usage: {\n        promptTokens: response.usage.prompt_tokens,\n        completionTokens: response.usage.completion_tokens,\n      },\n      rawCall: { rawPrompt, rawSettings },\n      rawResponse: { headers: responseHeaders },\n      response: getResponseMetadata(response),\n      warnings,\n    };\n  }\n\n  async doStream(\n    options: Parameters<LanguageModelV1['doStream']>[0],\n  ): Promise<Awaited<ReturnType<LanguageModelV1['doStream']>>> {\n    const { args, warnings } = this.getArgs(options);\n\n    const { responseHeaders, value: response } = await postJsonToApi({\n      url: `${this.config.baseURL}/chat/completions`,\n      headers: combineHeaders(this.config.headers(), options.headers),\n      body: { ...args, stream: true },\n      failedResponseHandler: mistralFailedResponseHandler,\n      successfulResponseHandler: createEventSourceResponseHandler(\n        mistralChatChunkSchema,\n      ),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    const { messages: rawPrompt, ...rawSettings } = args;\n\n    let finishReason: LanguageModelV1FinishReason = 'unknown';\n    let usage: { promptTokens: number; completionTokens: number } = {\n      promptTokens: Number.NaN,\n      completionTokens: Number.NaN,\n    };\n    let chunkNumber = 0;\n    let trimLeadingSpace = false;\n\n    return {\n      stream: response.pipeThrough(\n        new TransformStream<\n          ParseResult<z.infer<typeof mistralChatChunkSchema>>,\n          LanguageModelV1StreamPart\n        >({\n          transform(chunk, controller) {\n            if (!chunk.success) {\n              controller.enqueue({ type: 'error', error: chunk.error });\n              return;\n            }\n\n            chunkNumber++;\n\n            const value = chunk.value;\n\n            if (chunkNumber === 1) {\n              controller.enqueue({\n                type: 'response-metadata',\n                ...getResponseMetadata(value),\n              });\n            }\n\n            if (value.usage != null) {\n              usage = {\n                promptTokens: value.usage.prompt_tokens,\n                completionTokens: value.usage.completion_tokens,\n              };\n            }\n\n            const choice = value.choices[0];\n\n            if (choice?.finish_reason != null) {\n              finishReason = mapMistralFinishReason(choice.finish_reason);\n            }\n\n            if (choice?.delta == null) {\n              return;\n            }\n\n            const delta = choice.delta;\n\n            // when there is a trailing assistant message, mistral will send the\n            // content of that message again. we skip this repeated content to\n            // avoid duplication, e.g. in continuation mode.\n            if (chunkNumber <= 2) {\n              const lastMessage = rawPrompt[rawPrompt.length - 1];\n\n              if (\n                lastMessage.role === 'assistant' &&\n                delta.content === lastMessage.content.trimEnd()\n              ) {\n                // Mistral moves the trailing space from the prefix to the next chunk.\n                // We trim the leading space to avoid duplication.\n                if (delta.content.length < lastMessage.content.length) {\n                  trimLeadingSpace = true;\n                }\n\n                // skip the repeated content:\n                return;\n              }\n            }\n\n            if (delta.content != null) {\n              controller.enqueue({\n                type: 'text-delta',\n                textDelta: trimLeadingSpace\n                  ? delta.content.trimStart()\n                  : delta.content,\n              });\n\n              trimLeadingSpace = false;\n            }\n\n            if (delta.tool_calls != null) {\n              for (const toolCall of delta.tool_calls) {\n                // mistral tool calls come in one piece:\n                controller.enqueue({\n                  type: 'tool-call-delta',\n                  toolCallType: 'function',\n                  toolCallId: toolCall.id,\n                  toolName: toolCall.function.name,\n                  argsTextDelta: toolCall.function.arguments,\n                });\n                controller.enqueue({\n                  type: 'tool-call',\n                  toolCallType: 'function',\n                  toolCallId: toolCall.id,\n                  toolName: toolCall.function.name,\n                  args: toolCall.function.arguments,\n                });\n              }\n            }\n          },\n\n          flush(controller) {\n            controller.enqueue({ type: 'finish', finishReason, usage });\n          },\n        }),\n      ),\n      rawCall: { rawPrompt, rawSettings },\n      rawResponse: { headers: responseHeaders },\n      warnings,\n    };\n  }\n}\n\n// limited version of the schema, focussed on what is needed for the implementation\n// this approach limits breakages when the API changes and increases efficiency\nconst mistralChatResponseSchema = z.object({\n  id: z.string().nullish(),\n  created: z.number().nullish(),\n  model: z.string().nullish(),\n  choices: z.array(\n    z.object({\n      message: z.object({\n        role: z.literal('assistant'),\n        content: z.string().nullable(),\n        tool_calls: z\n          .array(\n            z.object({\n              id: z.string(),\n              function: z.object({ name: z.string(), arguments: z.string() }),\n            }),\n          )\n          .nullish(),\n      }),\n      index: z.number(),\n      finish_reason: z.string().nullish(),\n    }),\n  ),\n  object: z.literal('chat.completion'),\n  usage: z.object({\n    prompt_tokens: z.number(),\n    completion_tokens: z.number(),\n  }),\n});\n\n// limited version of the schema, focussed on what is needed for the implementation\n// this approach limits breakages when the API changes and increases efficiency\nconst mistralChatChunkSchema = z.object({\n  id: z.string().nullish(),\n  created: z.number().nullish(),\n  model: z.string().nullish(),\n  choices: z.array(\n    z.object({\n      delta: z.object({\n        role: z.enum(['assistant']).optional(),\n        content: z.string().nullish(),\n        tool_calls: z\n          .array(\n            z.object({\n              id: z.string(),\n              function: z.object({ name: z.string(), arguments: z.string() }),\n            }),\n          )\n          .nullish(),\n      }),\n      finish_reason: z.string().nullish(),\n      index: z.number(),\n    }),\n  ),\n  usage: z\n    .object({\n      prompt_tokens: z.number(),\n      completion_tokens: z.number(),\n    })\n    .nullish(),\n});\n\nfunction prepareToolsAndToolChoice(\n  mode: Parameters<LanguageModelV1['doGenerate']>[0]['mode'] & {\n    type: 'regular';\n  },\n) {\n  // when the tools array is empty, change it to undefined to prevent errors:\n  const tools = mode.tools?.length ? mode.tools : undefined;\n\n  if (tools == null) {\n    return { tools: undefined, tool_choice: undefined };\n  }\n\n  const mappedTools = tools.map(tool => ({\n    type: 'function',\n    function: {\n      name: tool.name,\n      description: tool.description,\n      parameters: tool.parameters,\n    },\n  }));\n\n  const toolChoice = mode.toolChoice;\n\n  if (toolChoice == null) {\n    return { tools: mappedTools, tool_choice: undefined };\n  }\n\n  const type = toolChoice.type;\n\n  switch (type) {\n    case 'auto':\n    case 'none':\n      return { tools: mappedTools, tool_choice: type };\n    case 'required':\n      return { tools: mappedTools, tool_choice: 'any' };\n\n    // mistral does not support tool mode directly,\n    // so we filter the tools and force the tool choice through 'any'\n    case 'tool':\n      return {\n        tools: mappedTools.filter(\n          tool => tool.function.name === toolChoice.toolName,\n        ),\n        tool_choice: 'any',\n      };\n    default: {\n      const _exhaustiveCheck: never = type;\n      throw new Error(`Unsupported tool choice type: ${_exhaustiveCheck}`);\n    }\n  }\n}\n", "import {\n  LanguageModelV1Prompt,\n  UnsupportedFunctionalityError,\n} from '@ai-sdk/provider';\nimport { convertUint8ArrayToBase64 } from '@ai-sdk/provider-utils';\nimport { MistralPrompt } from './mistral-chat-prompt';\n\nexport function convertToMistralChatMessages(\n  prompt: LanguageModelV1Prompt,\n): MistralPrompt {\n  const messages: MistralPrompt = [];\n\n  for (let i = 0; i < prompt.length; i++) {\n    const { role, content } = prompt[i];\n    const isLastMessage = i === prompt.length - 1;\n\n    switch (role) {\n      case 'system': {\n        messages.push({ role: 'system', content });\n        break;\n      }\n\n      case 'user': {\n        messages.push({\n          role: 'user',\n          content: content.map(part => {\n            switch (part.type) {\n              case 'text': {\n                return { type: 'text', text: part.text };\n              }\n              case 'image': {\n                return {\n                  type: 'image_url',\n                  image_url:\n                    part.image instanceof URL\n                      ? part.image.toString()\n                      : `data:${\n                          part.mimeType ?? 'image/jpeg'\n                        };base64,${convertUint8ArrayToBase64(part.image)}`,\n                };\n              }\n              case 'file': {\n                throw new UnsupportedFunctionalityError({\n                  functionality: 'File content parts in user messages',\n                });\n              }\n            }\n          }),\n        });\n        break;\n      }\n\n      case 'assistant': {\n        let text = '';\n        const toolCalls: Array<{\n          id: string;\n          type: 'function';\n          function: { name: string; arguments: string };\n        }> = [];\n\n        for (const part of content) {\n          switch (part.type) {\n            case 'text': {\n              text += part.text;\n              break;\n            }\n            case 'tool-call': {\n              toolCalls.push({\n                id: part.toolCallId,\n                type: 'function',\n                function: {\n                  name: part.toolName,\n                  arguments: JSON.stringify(part.args),\n                },\n              });\n              break;\n            }\n            default: {\n              const _exhaustiveCheck: never = part;\n              throw new Error(`Unsupported part: ${_exhaustiveCheck}`);\n            }\n          }\n        }\n\n        messages.push({\n          role: 'assistant',\n          content: text,\n          prefix: isLastMessage ? true : undefined,\n          tool_calls: toolCalls.length > 0 ? toolCalls : undefined,\n        });\n\n        break;\n      }\n      case 'tool': {\n        for (const toolResponse of content) {\n          messages.push({\n            role: 'tool',\n            name: toolResponse.toolName,\n            content: JSON.stringify(toolResponse.result),\n            tool_call_id: toolResponse.toolCallId,\n          });\n        }\n        break;\n      }\n      default: {\n        const _exhaustiveCheck: never = role;\n        throw new Error(`Unsupported role: ${_exhaustiveCheck}`);\n      }\n    }\n  }\n\n  return messages;\n}\n", "import { LanguageModelV1FinishReason } from '@ai-sdk/provider';\n\nexport function mapMistralFinishReason(\n  finishReason: string | null | undefined,\n): LanguageModelV1FinishReason {\n  switch (finishReason) {\n    case 'stop':\n      return 'stop';\n    case 'length':\n    case 'model_length':\n      return 'length';\n    case 'tool_calls':\n      return 'tool-calls';\n    default:\n      return 'unknown';\n  }\n}\n", "import { createJsonErrorResponseHandler } from '@ai-sdk/provider-utils';\nimport { z } from 'zod';\n\nconst mistralErrorDataSchema = z.object({\n  object: z.literal('error'),\n  message: z.string(),\n  type: z.string(),\n  param: z.string().nullable(),\n  code: z.string().nullable(),\n});\n\nexport type MistralErrorData = z.infer<typeof mistralErrorDataSchema>;\n\nexport const mistralFailedResponseHandler = createJsonErrorResponseHandler({\n  errorSchema: mistralErrorDataSchema,\n  errorToMessage: data => data.message,\n});\n", "export function getResponseMetadata({\n  id,\n  model,\n  created,\n}: {\n  id?: string | undefined | null;\n  created?: number | undefined | null;\n  model?: string | undefined | null;\n}) {\n  return {\n    id: id ?? undefined,\n    modelId: model ?? undefined,\n    timestamp: created != null ? new Date(created * 1000) : undefined,\n  };\n}\n", "import {\n  EmbeddingModelV1,\n  LanguageModelV1,\n  ProviderV1,\n} from '@ai-sdk/provider';\nimport {\n  FetchFunction,\n  loadApiKey,\n  withoutTrailingSlash,\n} from '@ai-sdk/provider-utils';\nimport { MistralChatLanguageModel } from './mistral-chat-language-model';\nimport {\n  MistralChatModelId,\n  MistralChatSettings,\n} from './mistral-chat-settings';\nimport { MistralEmbeddingModel } from './mistral-embedding-model';\nimport {\n  MistralEmbeddingModelId,\n  MistralEmbeddingSettings,\n} from './mistral-embedding-settings';\n\nexport interface MistralProvider extends ProviderV1 {\n  (\n    modelId: MistralChatModelId,\n    settings?: MistralChatSettings,\n  ): LanguageModelV1;\n\n  /**\nCreates a model for text generation.\n*/\n  languageModel(\n    modelId: MistralChatModelId,\n    settings?: MistralChatSettings,\n  ): LanguageModelV1;\n\n  /**\nCreates a model for text generation.\n*/\n  chat(\n    modelId: MistralChatModelId,\n    settings?: MistralChatSettings,\n  ): LanguageModelV1;\n\n  /**\n@deprecated Use `textEmbeddingModel()` instead.\n   */\n  embedding(\n    modelId: MistralEmbeddingModelId,\n    settings?: MistralEmbeddingSettings,\n  ): EmbeddingModelV1<string>;\n\n  /**\n@deprecated Use `textEmbeddingModel()` instead.\n   */\n  textEmbedding(\n    modelId: MistralEmbeddingModelId,\n    settings?: MistralEmbeddingSettings,\n  ): EmbeddingModelV1<string>;\n\n  textEmbeddingModel: (\n    modelId: MistralEmbeddingModelId,\n    settings?: MistralEmbeddingSettings,\n  ) => EmbeddingModelV1<string>;\n}\n\nexport interface MistralProviderSettings {\n  /**\nUse a different URL prefix for API calls, e.g. to use proxy servers.\nThe default prefix is `https://api.mistral.ai/v1`.\n   */\n  baseURL?: string;\n\n  /**\n@deprecated Use `baseURL` instead.\n   */\n  baseUrl?: string;\n\n  /**\nAPI key that is being send using the `Authorization` header.\nIt defaults to the `MISTRAL_API_KEY` environment variable.\n   */\n  apiKey?: string;\n\n  /**\nCustom headers to include in the requests.\n     */\n  headers?: Record<string, string>;\n\n  /**\nCustom fetch implementation. You can use it as a middleware to intercept requests,\nor to provide a custom fetch implementation for e.g. testing.\n    */\n  fetch?: FetchFunction;\n}\n\n/**\nCreate a Mistral AI provider instance.\n */\nexport function createMistral(\n  options: MistralProviderSettings = {},\n): MistralProvider {\n  const baseURL =\n    withoutTrailingSlash(options.baseURL ?? options.baseUrl) ??\n    'https://api.mistral.ai/v1';\n\n  const getHeaders = () => ({\n    Authorization: `Bearer ${loadApiKey({\n      apiKey: options.apiKey,\n      environmentVariableName: 'MISTRAL_API_KEY',\n      description: 'Mistral',\n    })}`,\n    ...options.headers,\n  });\n\n  const createChatModel = (\n    modelId: MistralChatModelId,\n    settings: MistralChatSettings = {},\n  ) =>\n    new MistralChatLanguageModel(modelId, settings, {\n      provider: 'mistral.chat',\n      baseURL,\n      headers: getHeaders,\n      fetch: options.fetch,\n    });\n\n  const createEmbeddingModel = (\n    modelId: MistralEmbeddingModelId,\n    settings: MistralEmbeddingSettings = {},\n  ) =>\n    new MistralEmbeddingModel(modelId, settings, {\n      provider: 'mistral.embedding',\n      baseURL,\n      headers: getHeaders,\n      fetch: options.fetch,\n    });\n\n  const provider = function (\n    modelId: MistralChatModelId,\n    settings?: MistralChatSettings,\n  ) {\n    if (new.target) {\n      throw new Error(\n        'The Mistral model function cannot be called with the new keyword.',\n      );\n    }\n\n    return createChatModel(modelId, settings);\n  };\n\n  provider.languageModel = createChatModel;\n  provider.chat = createChatModel;\n  provider.embedding = createEmbeddingModel;\n  provider.textEmbedding = createEmbeddingModel;\n  provider.textEmbeddingModel = createEmbeddingModel;\n\n  return provider as MistralProvider;\n}\n\n/**\nDefault Mistral provider instance.\n */\nexport const mistral = createMistral();\n", "import {\n  EmbeddingModelV1,\n  TooManyEmbeddingValuesForCallError,\n} from '@ai-sdk/provider';\nimport {\n  combineHeaders,\n  createJsonResponseHandler,\n  FetchFunction,\n  postJsonToApi,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod';\nimport {\n  MistralEmbeddingModelId,\n  MistralEmbeddingSettings,\n} from './mistral-embedding-settings';\nimport { mistralFailedResponseHandler } from './mistral-error';\n\ntype MistralEmbeddingConfig = {\n  provider: string;\n  baseURL: string;\n  headers: () => Record<string, string | undefined>;\n  fetch?: FetchFunction;\n};\n\nexport class MistralEmbeddingModel implements EmbeddingModelV1<string> {\n  readonly specificationVersion = 'v1';\n  readonly modelId: MistralEmbeddingModelId;\n\n  private readonly config: MistralEmbeddingConfig;\n  private readonly settings: MistralEmbeddingSettings;\n\n  get provider(): string {\n    return this.config.provider;\n  }\n\n  get maxEmbeddingsPerCall(): number {\n    return this.settings.maxEmbeddingsPerCall ?? 32;\n  }\n\n  get supportsParallelCalls(): boolean {\n    // Parallel calls are technically possible,\n    // but I have been hitting rate limits and disable them for now.\n    return this.settings.supportsParallelCalls ?? false;\n  }\n\n  constructor(\n    modelId: MistralEmbeddingModelId,\n    settings: MistralEmbeddingSettings,\n    config: MistralEmbeddingConfig,\n  ) {\n    this.modelId = modelId;\n    this.settings = settings;\n    this.config = config;\n  }\n\n  async doEmbed({\n    values,\n    abortSignal,\n    headers,\n  }: Parameters<EmbeddingModelV1<string>['doEmbed']>[0]): Promise<\n    Awaited<ReturnType<EmbeddingModelV1<string>['doEmbed']>>\n  > {\n    if (values.length > this.maxEmbeddingsPerCall) {\n      throw new TooManyEmbeddingValuesForCallError({\n        provider: this.provider,\n        modelId: this.modelId,\n        maxEmbeddingsPerCall: this.maxEmbeddingsPerCall,\n        values,\n      });\n    }\n\n    const { responseHeaders, value: response } = await postJsonToApi({\n      url: `${this.config.baseURL}/embeddings`,\n      headers: combineHeaders(this.config.headers(), headers),\n      body: {\n        model: this.modelId,\n        input: values,\n        encoding_format: 'float',\n      },\n      failedResponseHandler: mistralFailedResponseHandler,\n      successfulResponseHandler: createJsonResponseHandler(\n        MistralTextEmbeddingResponseSchema,\n      ),\n      abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    return {\n      embeddings: response.data.map(item => item.embedding),\n      usage: response.usage\n        ? { tokens: response.usage.prompt_tokens }\n        : undefined,\n      rawResponse: { headers: responseHeaders },\n    };\n  }\n}\n\n// minimal version of the schema, focussed on what is needed for the implementation\n// this approach limits breakages when the API changes and increases efficiency\nconst MistralTextEmbeddingResponseSchema = z.object({\n  data: z.array(z.object({ embedding: z.array(z.number()) })),\n  usage: z.object({ prompt_tokens: z.number() }).nullish(),\n});\n"],
  "mappings": ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AEOO,SAAS,6BACd,QACe;AACf,QAAM,WAA0B,CAAC;AAEjC,WAAS,IAAI,GAAG,IAAI,OAAO,QAAQ,KAAK;AACtC,UAAM,EAAE,MAAM,QAAQ,IAAI,OAAO,CAAC;AAClC,UAAM,gBAAgB,MAAM,OAAO,SAAS;AAE5C,YAAQ,MAAM;MACZ,KAAK,UAAU;AACb,iBAAS,KAAK,EAAE,MAAM,UAAU,QAAQ,CAAC;AACzC;MACF;MAEA,KAAK,QAAQ;AACX,iBAAS,KAAK;UACZ,MAAM;UACN,SAAS,QAAQ,IAAI,CAAA,SAAQ;AAzBvC,gBAAA;AA0BY,oBAAQ,KAAK,MAAM;cACjB,KAAK,QAAQ;AACX,uBAAO,EAAE,MAAM,QAAQ,MAAM,KAAK,KAAK;cACzC;cACA,KAAK,SAAS;AACZ,uBAAO;kBACL,MAAM;kBACN,WACE,KAAK,iBAAiB,MAClB,KAAK,MAAM,SAAS,IACpB,SACE,KAAA,KAAK,aAAL,OAAA,KAAiB,YACnB,WAAW,0BAA0B,KAAK,KAAK,CAAC;gBACxD;cACF;cACA,KAAK,QAAQ;AACX,sBAAM,IAAI,8BAA8B;kBACtC,eAAe;gBACjB,CAAC;cACH;YACF;UACF,CAAC;QACH,CAAC;AACD;MACF;MAEA,KAAK,aAAa;AAChB,YAAI,OAAO;AACX,cAAM,YAID,CAAC;AAEN,mBAAW,QAAQ,SAAS;AAC1B,kBAAQ,KAAK,MAAM;YACjB,KAAK,QAAQ;AACX,sBAAQ,KAAK;AACb;YACF;YACA,KAAK,aAAa;AAChB,wBAAU,KAAK;gBACb,IAAI,KAAK;gBACT,MAAM;gBACN,UAAU;kBACR,MAAM,KAAK;kBACX,WAAW,KAAK,UAAU,KAAK,IAAI;gBACrC;cACF,CAAC;AACD;YACF;YACA,SAAS;AACP,oBAAM,mBAA0B;AAChC,oBAAM,IAAI,MAAM,qBAAqB,gBAAgB,EAAE;YACzD;UACF;QACF;AAEA,iBAAS,KAAK;UACZ,MAAM;UACN,SAAS;UACT,QAAQ,gBAAgB,OAAO;UAC/B,YAAY,UAAU,SAAS,IAAI,YAAY;QACjD,CAAC;AAED;MACF;MACA,KAAK,QAAQ;AACX,mBAAW,gBAAgB,SAAS;AAClC,mBAAS,KAAK;YACZ,MAAM;YACN,MAAM,aAAa;YACnB,SAAS,KAAK,UAAU,aAAa,MAAM;YAC3C,cAAc,aAAa;UAC7B,CAAC;QACH;AACA;MACF;MACA,SAAS;AACP,cAAM,mBAA0B;AAChC,cAAM,IAAI,MAAM,qBAAqB,gBAAgB,EAAE;MACzD;IACF;EACF;AAEA,SAAO;AACT;AC9GO,SAAS,uBACd,cAC6B;AAC7B,UAAQ,cAAc;IACpB,KAAK;AACH,aAAO;IACT,KAAK;IACL,KAAK;AACH,aAAO;IACT,KAAK;AACH,aAAO;IACT;AACE,aAAO;EACX;AACF;ACbA,IAAM,yBAAyB,EAAE,OAAO;EACtC,QAAQ,EAAE,QAAQ,OAAO;EACzB,SAAS,EAAE,OAAO;EAClB,MAAM,EAAE,OAAO;EACf,OAAO,EAAE,OAAO,EAAE,SAAS;EAC3B,MAAM,EAAE,OAAO,EAAE,SAAS;AAC5B,CAAC;AAIM,IAAM,+BAA+B,+BAA+B;EACzE,aAAa;EACb,gBAAgB,CAAA,SAAQ,KAAK;AAC/B,CAAC;AChBM,SAAS,oBAAoB;EAClC;EACA;EACA;AACF,GAIG;AACD,SAAO;IACL,IAAI,MAAA,OAAA,KAAM;IACV,SAAS,SAAA,OAAA,QAAS;IAClB,WAAW,WAAW,OAAO,IAAI,KAAK,UAAU,GAAI,IAAI;EAC1D;AACF;AJiBO,IAAM,2BAAN,MAA0D;EAU/D,YACE,SACA,UACA,QACA;AAbF,SAAS,uBAAuB;AAChC,SAAS,8BAA8B;AACvC,SAAS,oBAAoB;AAY3B,SAAK,UAAU;AACf,SAAK,WAAW;AAChB,SAAK,SAAS;EAChB;EAEA,IAAI,WAAmB;AACrB,WAAO,KAAK,OAAO;EACrB;EAEQ,QAAQ;IACd;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;EACF,GAAiD;AAC/C,UAAM,OAAO,KAAK;AAElB,UAAM,WAAyC,CAAC;AAEhD,QAAI,QAAQ,MAAM;AAChB,eAAS,KAAK;QACZ,MAAM;QACN,SAAS;MACX,CAAC;IACH;AAEA,QAAI,oBAAoB,MAAM;AAC5B,eAAS,KAAK;QACZ,MAAM;QACN,SAAS;MACX,CAAC;IACH;AAEA,QAAI,mBAAmB,MAAM;AAC3B,eAAS,KAAK;QACZ,MAAM;QACN,SAAS;MACX,CAAC;IACH;AAEA,QAAI,iBAAiB,MAAM;AACzB,eAAS,KAAK;QACZ,MAAM;QACN,SAAS;MACX,CAAC;IACH;AAEA,QACE,kBAAkB,QAClB,eAAe,SAAS,UACxB,eAAe,UAAU,MACzB;AACA,eAAS,KAAK;QACZ,MAAM;QACN,SAAS;QACT,SAAS;MACX,CAAC;IACH;AAEA,UAAM,WAAW;;MAEf,OAAO,KAAK;;MAGZ,aAAa,KAAK,SAAS;;MAG3B,YAAY;MACZ;MACA,OAAO;MACP,aAAa;;MAGb,kBACE,kBAAA,OAAA,SAAA,eAAgB,UAAS,SAAS,EAAE,MAAM,cAAc,IAAI;;MAG9D,UAAU,6BAA6B,MAAM;IAC/C;AAEA,YAAQ,MAAM;MACZ,KAAK,WAAW;AACd,eAAO;UACL,MAAM,EAAE,GAAG,UAAU,GAAG,0BAA0B,IAAI,EAAE;UACxD;QACF;MACF;MAEA,KAAK,eAAe;AAClB,eAAO;UACL,MAAM;YACJ,GAAG;YACH,iBAAiB,EAAE,MAAM,cAAc;UACzC;UACA;QACF;MACF;MAEA,KAAK,eAAe;AAClB,eAAO;UACL,MAAM;YACJ,GAAG;YACH,aAAa;YACb,OAAO,CAAC,EAAE,MAAM,YAAY,UAAU,KAAK,KAAK,CAAC;UACnD;UACA;QACF;MACF;MAEA,SAAS;AACP,cAAM,mBAA0B;AAChC,cAAM,IAAI,MAAM,qBAAqB,gBAAgB,EAAE;MACzD;IACF;EACF;EAEA,MAAM,WACJ,SAC6D;AA3KjE,QAAA,IAAA;AA4KI,UAAM,EAAE,MAAM,SAAS,IAAI,KAAK,QAAQ,OAAO;AAE/C,UAAM,EAAE,iBAAiB,OAAO,SAAS,IAAI,MAAM,cAAc;MAC/D,KAAK,GAAG,KAAK,OAAO,OAAO;MAC3B,SAAS,eAAe,KAAK,OAAO,QAAQ,GAAG,QAAQ,OAAO;MAC9D,MAAM;MACN,uBAAuB;MACvB,2BAA2B;QACzB;MACF;MACA,aAAa,QAAQ;MACrB,OAAO,KAAK,OAAO;IACrB,CAAC;AAED,UAAM,EAAE,UAAU,WAAW,GAAG,YAAY,IAAI;AAChD,UAAM,SAAS,SAAS,QAAQ,CAAC;AACjC,QAAI,QAAO,KAAA,OAAO,QAAQ,YAAf,OAAA,KAA0B;AAKrC,UAAM,cAAc,UAAU,UAAU,SAAS,CAAC;AAClD,QACE,YAAY,SAAS,gBACrB,QAAA,OAAA,SAAA,KAAM,WAAW,YAAY,OAAA,IAC7B;AACA,aAAO,KAAK,MAAM,YAAY,QAAQ,MAAM;IAC9C;AAEA,WAAO;MACL;MACA,YAAW,KAAA,OAAO,QAAQ,eAAf,OAAA,SAAA,GAA2B,IAAI,CAAA,cAAa;QACrD,cAAc;QACd,YAAY,SAAS;QACrB,UAAU,SAAS,SAAS;QAC5B,MAAM,SAAS,SAAS;MAC1B,EAAA;MACA,cAAc,uBAAuB,OAAO,aAAa;MACzD,OAAO;QACL,cAAc,SAAS,MAAM;QAC7B,kBAAkB,SAAS,MAAM;MACnC;MACA,SAAS,EAAE,WAAW,YAAY;MAClC,aAAa,EAAE,SAAS,gBAAgB;MACxC,UAAU,oBAAoB,QAAQ;MACtC;IACF;EACF;EAEA,MAAM,SACJ,SAC2D;AAC3D,UAAM,EAAE,MAAM,SAAS,IAAI,KAAK,QAAQ,OAAO;AAE/C,UAAM,EAAE,iBAAiB,OAAO,SAAS,IAAI,MAAM,cAAc;MAC/D,KAAK,GAAG,KAAK,OAAO,OAAO;MAC3B,SAAS,eAAe,KAAK,OAAO,QAAQ,GAAG,QAAQ,OAAO;MAC9D,MAAM,EAAE,GAAG,MAAM,QAAQ,KAAK;MAC9B,uBAAuB;MACvB,2BAA2B;QACzB;MACF;MACA,aAAa,QAAQ;MACrB,OAAO,KAAK,OAAO;IACrB,CAAC;AAED,UAAM,EAAE,UAAU,WAAW,GAAG,YAAY,IAAI;AAEhD,QAAI,eAA4C;AAChD,QAAI,QAA4D;MAC9D,cAAc,OAAO;MACrB,kBAAkB,OAAO;IAC3B;AACA,QAAI,cAAc;AAClB,QAAI,mBAAmB;AAEvB,WAAO;MACL,QAAQ,SAAS;QACf,IAAI,gBAGF;UACA,UAAU,OAAO,YAAY;AAC3B,gBAAI,CAAC,MAAM,SAAS;AAClB,yBAAW,QAAQ,EAAE,MAAM,SAAS,OAAO,MAAM,MAAM,CAAC;AACxD;YACF;AAEA;AAEA,kBAAM,QAAQ,MAAM;AAEpB,gBAAI,gBAAgB,GAAG;AACrB,yBAAW,QAAQ;gBACjB,MAAM;gBACN,GAAG,oBAAoB,KAAK;cAC9B,CAAC;YACH;AAEA,gBAAI,MAAM,SAAS,MAAM;AACvB,sBAAQ;gBACN,cAAc,MAAM,MAAM;gBAC1B,kBAAkB,MAAM,MAAM;cAChC;YACF;AAEA,kBAAM,SAAS,MAAM,QAAQ,CAAC;AAE9B,iBAAI,UAAA,OAAA,SAAA,OAAQ,kBAAiB,MAAM;AACjC,6BAAe,uBAAuB,OAAO,aAAa;YAC5D;AAEA,iBAAI,UAAA,OAAA,SAAA,OAAQ,UAAS,MAAM;AACzB;YACF;AAEA,kBAAM,QAAQ,OAAO;AAKrB,gBAAI,eAAe,GAAG;AACpB,oBAAM,cAAc,UAAU,UAAU,SAAS,CAAC;AAElD,kBACE,YAAY,SAAS,eACrB,MAAM,YAAY,YAAY,QAAQ,QAAQ,GAC9C;AAGA,oBAAI,MAAM,QAAQ,SAAS,YAAY,QAAQ,QAAQ;AACrD,qCAAmB;gBACrB;AAGA;cACF;YACF;AAEA,gBAAI,MAAM,WAAW,MAAM;AACzB,yBAAW,QAAQ;gBACjB,MAAM;gBACN,WAAW,mBACP,MAAM,QAAQ,UAAU,IACxB,MAAM;cACZ,CAAC;AAED,iCAAmB;YACrB;AAEA,gBAAI,MAAM,cAAc,MAAM;AAC5B,yBAAW,YAAY,MAAM,YAAY;AAEvC,2BAAW,QAAQ;kBACjB,MAAM;kBACN,cAAc;kBACd,YAAY,SAAS;kBACrB,UAAU,SAAS,SAAS;kBAC5B,eAAe,SAAS,SAAS;gBACnC,CAAC;AACD,2BAAW,QAAQ;kBACjB,MAAM;kBACN,cAAc;kBACd,YAAY,SAAS;kBACrB,UAAU,SAAS,SAAS;kBAC5B,MAAM,SAAS,SAAS;gBAC1B,CAAC;cACH;YACF;UACF;UAEA,MAAM,YAAY;AAChB,uBAAW,QAAQ,EAAE,MAAM,UAAU,cAAc,MAAM,CAAC;UAC5D;QACF,CAAC;MACH;MACA,SAAS,EAAE,WAAW,YAAY;MAClC,aAAa,EAAE,SAAS,gBAAgB;MACxC;IACF;EACF;AACF;AAIA,IAAM,4BAA4BA,EAAE,OAAO;EACzC,IAAIA,EAAE,OAAO,EAAE,QAAQ;EACvB,SAASA,EAAE,OAAO,EAAE,QAAQ;EAC5B,OAAOA,EAAE,OAAO,EAAE,QAAQ;EAC1B,SAASA,EAAE;IACTA,EAAE,OAAO;MACP,SAASA,EAAE,OAAO;QAChB,MAAMA,EAAE,QAAQ,WAAW;QAC3B,SAASA,EAAE,OAAO,EAAE,SAAS;QAC7B,YAAYA,EACT;UACCA,EAAE,OAAO;YACP,IAAIA,EAAE,OAAO;YACb,UAAUA,EAAE,OAAO,EAAE,MAAMA,EAAE,OAAO,GAAG,WAAWA,EAAE,OAAO,EAAE,CAAC;UAChE,CAAC;QACH,EACC,QAAQ;MACb,CAAC;MACD,OAAOA,EAAE,OAAO;MAChB,eAAeA,EAAE,OAAO,EAAE,QAAQ;IACpC,CAAC;EACH;EACA,QAAQA,EAAE,QAAQ,iBAAiB;EACnC,OAAOA,EAAE,OAAO;IACd,eAAeA,EAAE,OAAO;IACxB,mBAAmBA,EAAE,OAAO;EAC9B,CAAC;AACH,CAAC;AAID,IAAM,yBAAyBA,EAAE,OAAO;EACtC,IAAIA,EAAE,OAAO,EAAE,QAAQ;EACvB,SAASA,EAAE,OAAO,EAAE,QAAQ;EAC5B,OAAOA,EAAE,OAAO,EAAE,QAAQ;EAC1B,SAASA,EAAE;IACTA,EAAE,OAAO;MACP,OAAOA,EAAE,OAAO;QACd,MAAMA,EAAE,KAAK,CAAC,WAAW,CAAC,EAAE,SAAS;QACrC,SAASA,EAAE,OAAO,EAAE,QAAQ;QAC5B,YAAYA,EACT;UACCA,EAAE,OAAO;YACP,IAAIA,EAAE,OAAO;YACb,UAAUA,EAAE,OAAO,EAAE,MAAMA,EAAE,OAAO,GAAG,WAAWA,EAAE,OAAO,EAAE,CAAC;UAChE,CAAC;QACH,EACC,QAAQ;MACb,CAAC;MACD,eAAeA,EAAE,OAAO,EAAE,QAAQ;MAClC,OAAOA,EAAE,OAAO;IAClB,CAAC;EACH;EACA,OAAOA,EACJ,OAAO;IACN,eAAeA,EAAE,OAAO;IACxB,mBAAmBA,EAAE,OAAO;EAC9B,CAAC,EACA,QAAQ;AACb,CAAC;AAED,SAAS,0BACP,MAGA;AAtaF,MAAA;AAwaE,QAAM,UAAQ,KAAA,KAAK,UAAL,OAAA,SAAA,GAAY,UAAS,KAAK,QAAQ;AAEhD,MAAI,SAAS,MAAM;AACjB,WAAO,EAAE,OAAO,QAAW,aAAa,OAAU;EACpD;AAEA,QAAM,cAAc,MAAM,IAAI,CAAA,UAAS;IACrC,MAAM;IACN,UAAU;MACR,MAAM,KAAK;MACX,aAAa,KAAK;MAClB,YAAY,KAAK;IACnB;EACF,EAAE;AAEF,QAAM,aAAa,KAAK;AAExB,MAAI,cAAc,MAAM;AACtB,WAAO,EAAE,OAAO,aAAa,aAAa,OAAU;EACtD;AAEA,QAAM,OAAO,WAAW;AAExB,UAAQ,MAAM;IACZ,KAAK;IACL,KAAK;AACH,aAAO,EAAE,OAAO,aAAa,aAAa,KAAK;IACjD,KAAK;AACH,aAAO,EAAE,OAAO,aAAa,aAAa,MAAM;IAIlD,KAAK;AACH,aAAO;QACL,OAAO,YAAY;UACjB,CAAA,SAAQ,KAAK,SAAS,SAAS,WAAW;QAC5C;QACA,aAAa;MACf;IACF,SAAS;AACP,YAAM,mBAA0B;AAChC,YAAM,IAAI,MAAM,iCAAiC,gBAAgB,EAAE;IACrE;EACF;AACF;ADzcO,IAAM,UAAN,MAAc;;;;EAanB,YAAY,UAAmC,CAAC,GAAG;AAxBrD,QAAA,IAAA;AAyBI,SAAK,WACH,KAAA,sBAAqB,KAAA,QAAQ,YAAR,OAAA,KAAmB,QAAQ,OAAO,MAAvD,OAAA,KACA;AAEF,SAAK,SAAS,QAAQ;AACtB,SAAK,UAAU,QAAQ;EACzB;EAEA,IAAY,aAAa;AACvB,WAAO;MACL,SAAS,KAAK;MACd,SAAS,OAAO;QACd,eAAe,UAAU,WAAW;UAClC,QAAQ,KAAK;UACb,yBAAyB;UACzB,aAAa;QACf,CAAC,CAAC;QACF,GAAG,KAAK;MACV;IACF;EACF;EAEA,KAAK,SAA6B,WAAgC,CAAC,GAAG;AACpE,WAAO,IAAI,yBAAyB,SAAS,UAAU;MACrD,UAAU;MACV,GAAG,KAAK;IACV,CAAC;EACH;AACF;AO7BO,IAAM,wBAAN,MAAgE;EAqBrE,YACE,SACA,UACA,QACA;AAxBF,SAAS,uBAAuB;AAyB9B,SAAK,UAAU;AACf,SAAK,WAAW;AAChB,SAAK,SAAS;EAChB;EAtBA,IAAI,WAAmB;AACrB,WAAO,KAAK,OAAO;EACrB;EAEA,IAAI,uBAA+B;AAnCrC,QAAA;AAoCI,YAAO,KAAA,KAAK,SAAS,yBAAd,OAAA,KAAsC;EAC/C;EAEA,IAAI,wBAAiC;AAvCvC,QAAA;AA0CI,YAAO,KAAA,KAAK,SAAS,0BAAd,OAAA,KAAuC;EAChD;EAYA,MAAM,QAAQ;IACZ;IACA;IACA;EACF,GAEE;AACA,QAAI,OAAO,SAAS,KAAK,sBAAsB;AAC7C,YAAM,IAAI,mCAAmC;QAC3C,UAAU,KAAK;QACf,SAAS,KAAK;QACd,sBAAsB,KAAK;QAC3B;MACF,CAAC;IACH;AAEA,UAAM,EAAE,iBAAiB,OAAO,SAAS,IAAI,MAAMC,cAAc;MAC/D,KAAK,GAAG,KAAK,OAAO,OAAO;MAC3B,SAASC,eAAe,KAAK,OAAO,QAAQ,GAAG,OAAO;MACtD,MAAM;QACJ,OAAO,KAAK;QACZ,OAAO;QACP,iBAAiB;MACnB;MACA,uBAAuB;MACvB,2BAA2BC;QACzB;MACF;MACA;MACA,OAAO,KAAK,OAAO;IACrB,CAAC;AAED,WAAO;MACL,YAAY,SAAS,KAAK,IAAI,CAAA,SAAQ,KAAK,SAAS;MACpD,OAAO,SAAS,QACZ,EAAE,QAAQ,SAAS,MAAM,cAAc,IACvC;MACJ,aAAa,EAAE,SAAS,gBAAgB;IAC1C;EACF;AACF;AAIA,IAAM,qCAAqCH,EAAE,OAAO;EAClD,MAAMA,EAAE,MAAMA,EAAE,OAAO,EAAE,WAAWA,EAAE,MAAMA,EAAE,OAAO,CAAC,EAAE,CAAC,CAAC;EAC1D,OAAOA,EAAE,OAAO,EAAE,eAAeA,EAAE,OAAO,EAAE,CAAC,EAAE,QAAQ;AACzD,CAAC;ADJM,SAAS,cACd,UAAmC,CAAC,GACnB;AApGnB,MAAA,IAAA;AAqGE,QAAM,WACJ,KAAAI,sBAAqB,KAAA,QAAQ,YAAR,OAAA,KAAmB,QAAQ,OAAO,MAAvD,OAAA,KACA;AAEF,QAAM,aAAa,OAAO;IACxB,eAAe,UAAUC,WAAW;MAClC,QAAQ,QAAQ;MAChB,yBAAyB;MACzB,aAAa;IACf,CAAC,CAAC;IACF,GAAG,QAAQ;EACb;AAEA,QAAM,kBAAkB,CACtB,SACA,WAAgC,CAAC,MAEjC,IAAI,yBAAyB,SAAS,UAAU;IAC9C,UAAU;IACV;IACA,SAAS;IACT,OAAO,QAAQ;EACjB,CAAC;AAEH,QAAM,uBAAuB,CAC3B,SACA,WAAqC,CAAC,MAEtC,IAAI,sBAAsB,SAAS,UAAU;IAC3C,UAAU;IACV;IACA,SAAS;IACT,OAAO,QAAQ;EACjB,CAAC;AAEH,QAAM,WAAW,SACf,SACA,UACA;AACA,QAAI,YAAY;AACd,YAAM,IAAI;QACR;MACF;IACF;AAEA,WAAO,gBAAgB,SAAS,QAAQ;EAC1C;AAEA,WAAS,gBAAgB;AACzB,WAAS,OAAO;AAChB,WAAS,YAAY;AACrB,WAAS,gBAAgB;AACzB,WAAS,qBAAqB;AAE9B,SAAO;AACT;AAKO,IAAM,UAAU,cAAc;",
  "names": ["z", "postJsonToApi", "combineHeaders", "createJsonResponseHandler", "withoutTrailingSlash", "loadApiKey"]
}
